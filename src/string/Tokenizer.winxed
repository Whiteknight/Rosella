/* Tokenizer Base Class
    Tokenizers break strings up into tokens according to predefined rules,
    starting with the start of the string and creating tokens until the
    input data is exhausted.

    This class is the abstract parent type of various tokenizers. Do not
    use this type directly, use a subclass instead.
*/
// TODO: Include line-number/filename information in tokens, if possible
class Rosella.String.Tokenizer
{
    var tokens; // An array of available tokens
    var data;   // The input data. Typically a string
    var map;    // A map of pre-defined tokens.

    // Constructor
    function Tokenizer()
    {
        self.tokens = [];
        self.data = null;
        self.map = {};
    }

    /* Public API Functions
    */

    // Add more string data to the end of the current input sequence.
    function add_data(string str)
    {
        if (self.data == null)
            self.data = str;
        else {
            string data = self.data;
            self.data = data + str;
        }
    }

    // Set the current data, replacing the previous value.
    function set_data(string str)
    {
        self.data = str;
    }

    // Get the remaining data out of the tokenizer, and empty the tokenizer
    // input buffer.
    function get_all_data()
    {
        string d = self.data;
        self.data = null;
        return d;
    }

    // Create a token mapping. When the given input sequence is encountered,
    // return the predefined token instead of creating a new one.
    function map_token(string typename, string key, var metadata)
    {
        self.map[key] = self.__build_token(typename, key, metadata);
    }

    // Determine if we have tokens or input data still to be processed.
    // returns 1 if there is data, 0 otherwise
    function has_tokens()
    {
        if (elements(self.tokens) > 0)
            return 1;
        if (self.data != null && length(self.data) > 0)
            return 1;
        return 0;
    }

    // Get a token from the input data.
    function get_token()
    {
        if (elements(self.tokens) >= 1)
            return shift_p(self.tokens);
        if (self.data != null && self.data != "")
            return self.lex_next_token();
        return null;
    }

    // Completely tokenize the entire input and return all tokens as an
    // array
    function all_tokens()
    {
        var tokens = [];
        while (self.has_tokens()) {
            var t = self.get_token();
            push(tokens, t);
        }
        return tokens;
    }

    // Use lexing rules to get the next token from the beginning of the
    // input data. Must be subclassed
    function lex_next_token()
    {
        Rosella.Error.must_subclass(__CLASS__);
    }

    // Unget a token, pushing it onto a queue for later retrieval
    function unget_token(var token)
    {
        push(self.tokens, token);
    }

    /* Private / Protected Methods
        These methods are private helpers or internal methods and should
        only be used here and by subclasses.
    */

    // Get a new token for the given input text. Search the map first, and
    // create a new token otherwise.
    function __new_token(string text, var metadata)
    {
        if (exists self.map[text])
            return self.map[text];
        string string_null = null;
        return self.__build_token(string_null, text, metadata);
    }

    // Create a new token. Can be subclassed to create tokens of a new
    // type. By default, creates a Rosella.String.Tokenizer.Token.
    function __build_token(string typename, string text, var metadata)
    {
        return new Rosella.String.Tokenizer.Token(typename, text, metadata);
    }

    // Helper routine. Get the first n characters from the front of the
    // input data.
    function __get_chars(int count, int skip = 0)
    {
        string str = self.data;
        int len = length(str);
        if (count >= len) {
            self.data = null;
            return str;
        }
        self.data = substr(str, count + skip);
        return substr(str, 0, count);
    }

    function get_iter[vtable]()
    {
        return new Rosella.String.Tokenizer.Iterator(self);
    }
}
